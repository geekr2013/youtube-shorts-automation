"""
AAGAG ì½˜í…ì¸  ìˆ˜ì§‘ê¸° - ìµœì¢… ì•ˆì • ë²„ì „
ì œëª© í•„í„°ë§ ì—†ì´ ëª¨ë“  ê²Œì‹œë¬¼ì˜ ì‹¤ì œ ë‹¤ìš´ë¡œë“œ ë§í¬ í™•ì¸
"""

import os
import re
import time
from pathlib import Path
from typing import List, Dict, Optional
import logging
from playwright.sync_api import sync_playwright, TimeoutError as PlaywrightTimeout

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class AAGAGCollector:
    """AAGAG ì‚¬ì´íŠ¸ í¬ë¡¤ëŸ¬ - ì‹¤ì œ ë‹¤ìš´ë¡œë“œ ë§í¬ ê¸°ë°˜"""
    
    def __init__(self, base_url: str = "https://aagag.com/issue/"):
        self.base_url = base_url
        self.download_dir = Path("data/videos")
        self.download_dir.mkdir(parents=True, exist_ok=True)
        
        # ë‹¤ìš´ë¡œë“œ ì´ë ¥ ê´€ë¦¬
        self.history_file = Path("data/download_history.json")
        self.downloaded_urls = self._load_history()
    
    def _load_history(self) -> set:
        """ë‹¤ìš´ë¡œë“œ ì´ë ¥ ë¡œë“œ"""
        if self.history_file.exists():
            import json
            try:
                with open(self.history_file, 'r') as f:
                    return set(json.load(f))
            except:
                return set()
        return set()
    
    def _save_history(self):
        """ë‹¤ìš´ë¡œë“œ ì´ë ¥ ì €ì¥"""
        import json
        self.history_file.parent.mkdir(parents=True, exist_ok=True)
        with open(self.history_file, 'w') as f:
            json.dump(list(self.downloaded_urls), f, indent=2)
    
    def collect_and_download(self, max_videos: int = 5) -> List[Dict]:
        """
        ê²Œì‹œë¬¼ ìˆ˜ì§‘ ë° ë‹¤ìš´ë¡œë“œ
        
        Args:
            max_videos: ìµœëŒ€ ìˆ˜ì§‘ ê°œìˆ˜
            
        Returns:
            ë‹¤ìš´ë¡œë“œëœ ë¹„ë””ì˜¤ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        logger.info("\n" + "="*60)
        logger.info(f"ğŸš€ AAGAG ë¹„ë””ì˜¤/GIF ìˆ˜ì§‘ ì‹œì‘ (ìµœëŒ€ {max_videos}ê°œ)")
        logger.info("="*60 + "\n")
        
        collected_videos = []
        
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=True)
            page = browser.new_page()
            
            try:
                # 1. ë©”ì¸ í˜ì´ì§€ì—ì„œ ê²Œì‹œë¬¼ ë§í¬ ìˆ˜ì§‘
                logger.info("ğŸ“¡ AAGAG ë©”ì¸ í˜ì´ì§€ í¬ë¡¤ë§ ì‹œì‘...")
                page.goto(self.base_url, wait_until="domcontentloaded", timeout=30000)
                page.wait_for_timeout(2000)
                
                # ê²Œì‹œë¬¼ ë§í¬ ì¶”ì¶œ (ëª¨ë“  ê²Œì‹œë¬¼)
                post_links = page.eval_on_selector_all(
                    'a.article, a.article.t',
                    'elements => elements.map(e => e.href)'
                )
                
                logger.info(f"âœ… ë°œê²¬í•œ ê²Œì‹œë¬¼ ë§í¬: {len(post_links)}ê°œ")
                
                # 2. ê° ê²Œì‹œë¬¼ ë°©ë¬¸í•˜ì—¬ ì‹¤ì œ ë‹¤ìš´ë¡œë“œ ë§í¬ í™•ì¸
                checked_count = 0
                for post_url in post_links:
                    if len(collected_videos) >= max_videos:
                        break
                    
                    # ì´ë¯¸ ë‹¤ìš´ë¡œë“œí•œ ê²Œì‹œë¬¼ ìŠ¤í‚µ
                    if post_url in self.downloaded_urls:
                        continue
                    
                    checked_count += 1
                    logger.info(f"ğŸ” [{checked_count}/{len(post_links)}] ê²Œì‹œë¬¼ í™•ì¸ ì¤‘: {post_url}")
                    
                    try:
                        # ê²Œì‹œë¬¼ ìƒì„¸ í˜ì´ì§€ ë°©ë¬¸
                        page.goto(post_url, wait_until="domcontentloaded", timeout=15000)
                        page.wait_for_timeout(1000)
                        
                        # ì‹¤ì œ ë‹¤ìš´ë¡œë“œ ë§í¬ ì°¾ê¸°
                        download_url = self._extract_download_url(page)
                        
                        if download_url:
                            # MP4 ë˜ëŠ” GIFì¸ì§€ í™•ì¸
                            file_ext = self._get_file_extension(download_url)
                            
                            if file_ext in ['.mp4', '.gif']:
                                # ì œëª© ì¶”ì¶œ (ê²Œì‹œë¬¼ í˜ì´ì§€ì˜ ì‹¤ì œ ì œëª©)
                                title = self._extract_title(page, download_url)
                                
                                logger.info(f"âœ… ë°œê²¬: {title} ({file_ext})")
                                
                                # ë‹¤ìš´ë¡œë“œ
                                video_path = self._download_file(download_url, title, file_ext)
                                
                                if video_path:
                                    # GIF â†’ MP4 ë³€í™˜
                                    if file_ext == '.gif':
                                        video_path = self._convert_gif_to_mp4(video_path)
                                    
                                    collected_videos.append({
                                        'title': title,
                                        'video_path': str(video_path),
                                        'source_url': post_url,
                                        'download_url': download_url,
                                        'type': file_ext
                                    })
                                    
                                    # ì´ë ¥ì— ì¶”ê°€
                                    self.downloaded_urls.add(post_url)
                                    self._save_history()
                            else:
                                logger.debug(f"â­ï¸ ìŠ¤í‚µ (ì§€ì›í•˜ì§€ ì•ŠëŠ” í˜•ì‹): {file_ext}")
                        else:
                            logger.debug(f"â­ï¸ ìŠ¤í‚µ (ë‹¤ìš´ë¡œë“œ ë§í¬ ì—†ìŒ)")
                    
                    except Exception as e:
                        logger.warning(f"âš ï¸ ê²Œì‹œë¬¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                        continue
                
                logger.info(f"\nâœ… ë¹„ë””ì˜¤/GIF ê²Œì‹œë¬¼ {len(collected_videos)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
                
            except Exception as e:
                logger.error(f"âŒ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
            
            finally:
                browser.close()
        
        return collected_videos
    
    def _extract_download_url(self, page) -> Optional[str]:
        """ê²Œì‹œë¬¼ í˜ì´ì§€ì—ì„œ ì‹¤ì œ ë‹¤ìš´ë¡œë“œ URL ì¶”ì¶œ"""
        try:
            # ë°©ë²• 1: i.aagag.com ì§ì ‘ ë§í¬ ì°¾ê¸°
            links = page.eval_on_selector_all(
                'a',
                'elements => elements.map(e => e.href)'
            )
            
            for link in links:
                if 'i.aagag.com' in link and (link.endswith('.mp4') or link.endswith('.gif')):
                    return link
            
            # ë°©ë²• 2: í˜ì´ì§€ ì†ŒìŠ¤ì—ì„œ ì •ê·œì‹ìœ¼ë¡œ ì°¾ê¸°
            content = page.content()
            patterns = [
                r'https://i\.aagag\.com/[A-Za-z0-9]+\.(mp4|gif)',
                r'href="(https://i\.aagag\.com/[^"]+\.(mp4|gif))"',
                r"src='(https://i\.aagag\.com/[^']+\.(mp4|gif))'"
            ]
            
            for pattern in patterns:
                match = re.search(pattern, content)
                if match:
                    return match.group(1) if match.lastindex else match.group(0)
            
            return None
        
        except Exception as e:
            logger.debug(f"ë‹¤ìš´ë¡œë“œ URL ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def _get_file_extension(self, url: str) -> str:
        """URLì—ì„œ íŒŒì¼ í™•ì¥ì ì¶”ì¶œ"""
        match = re.search(r'\.(mp4|gif|webm|avi)(?:\?|$)', url.lower())
        return f".{match.group(1)}" if match else ""
    
    def _extract_title(self, page, download_url: str) -> str:
        """ì œëª© ì¶”ì¶œ (í˜ì´ì§€ ì œëª© ë˜ëŠ” íŒŒì¼ëª…)"""
        try:
            # ë°©ë²• 1: í˜ì´ì§€ ì œëª©
            title = page.title()
            if title and title != "AAGAG":
                # ë¶ˆí•„ìš”í•œ ì ‘ë¯¸ì‚¬ ì œê±°
                title = re.sub(r'\s*-\s*AAGAG.*$', '', title)
                # íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•œ ë¬¸ì ì œê±°
                title = re.sub(r'[<>:"/\\|?*]', '', title)
                return title.strip()[:50]  # ìµœëŒ€ 50ì
            
            # ë°©ë²• 2: URLì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ
            filename = download_url.split('/')[-1].split('?')[0]
            return re.sub(r'\.(mp4|gif)$', '', filename)
        
        except:
            return f"video_{int(time.time())}"
    
    def _download_file(self, url: str, title: str, ext: str) -> Optional[Path]:
        """íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
        try:
            import requests
            
            # ì•ˆì „í•œ íŒŒì¼ëª… ìƒì„±
            safe_title = re.sub(r'[<>:"/\\|?*]', '', title)
            filename = f"{safe_title}{ext}"
            filepath = self.download_dir / filename
            
            # íŒŒì¼ëª… ì¤‘ë³µ ë°©ì§€
            counter = 1
            while filepath.exists():
                filename = f"{safe_title}_{counter}{ext}"
                filepath = self.download_dir / filename
                counter += 1
            
            logger.info(f"ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì¤‘: {filename}")
            
            response = requests.get(url, timeout=30)
            response.raise_for_status()
            
            with open(filepath, 'wb') as f:
                f.write(response.content)
            
            logger.info(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {filepath} ({len(response.content) / 1024 / 1024:.2f} MB)")
            return filepath
        
        except Exception as e:
            logger.error(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def _convert_gif_to_mp4(self, gif_path: Path) -> Path:
        """GIFë¥¼ MP4ë¡œ ë³€í™˜"""
        try:
            import subprocess
            
            mp4_path = gif_path.with_suffix('.mp4')
            
            logger.info(f"ğŸ”„ GIF â†’ MP4 ë³€í™˜ ì¤‘: {gif_path.name}")
            
            # YouTube Shorts í˜¸í™˜ ì„¤ì •
            cmd = [
                'ffmpeg',
                '-i', str(gif_path),
                '-vf', 'scale=1080:1920:force_original_aspect_ratio=decrease,pad=1080:1920:(ow-iw)/2:(oh-ih)/2,setsar=1',
                '-c:v', 'libx264',
                '-pix_fmt', 'yuv420p',
                '-preset', 'medium',
                '-crf', '23',
                '-movflags', '+faststart',
                '-y',
                str(mp4_path)
            ]
            
            subprocess.run(cmd, check=True, capture_output=True)
            
            # ì›ë³¸ GIF ì‚­ì œ
            gif_path.unlink()
            
            logger.info(f"âœ… ë³€í™˜ ì™„ë£Œ: {mp4_path.name}")
            return mp4_path
        
        except Exception as e:
            logger.error(f"âŒ GIF ë³€í™˜ ì‹¤íŒ¨: {e}")
            return gif_path


def main():
    """í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜"""
    collector = AAGAGCollector()
    videos = collector.collect_and_download(max_videos=3)
    
    print(f"\nìˆ˜ì§‘ëœ ë¹„ë””ì˜¤: {len(videos)}ê°œ")
    for video in videos:
        print(f"  - {video['title']}: {video['video_path']}")


if __name__ == "__main__":
    main()
